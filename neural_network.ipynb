{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce41e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My notes from watching https://www.youtube.com/watch?v=PaCmpygFfXo\n",
    "# The spelled-out intro to language modeling: building makemore by Andrej Karpathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d079bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc478131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast the bigram character level language modeling into neural network framework\n",
    "# it receives a single character as input, then there is a neural network with some weights(parameters) w\n",
    "# and then it will output the probability distribution over the next character in the sequence\n",
    "# which character is likely to follow the input character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4769dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# first create the training set of bigrams (x, y)\n",
    "# we are given x, we are trying to predict y\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "\n",
    "# finally add the start / end token\n",
    "stoi['.'] = 0\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ae4550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf95f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eddb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \"emma\", there are 5 separate input examples\n",
    "# when the input is integer 0, the desired label is integer 5.\n",
    "# when the input is 5, we want the weights to be arranged so that 13 gets a very high probability\n",
    "# when 13 is input, we want 13 to have a high probability\n",
    "# when 13 is input, we also want 1 to have a high probability\n",
    "# when 1 is input, we want 0 to have a high probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d81218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is torch.tensor\n",
    "# there is torch.Tensor (tensor class that you can construct)\n",
    "# what's the difference? \n",
    "# torch.tensor infers the dtype while torch.Tensor returns a float\n",
    "# advised that you use torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "005389c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "# we want to cast to float for some reason to feed into the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d5218d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d24a321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcf99a246a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd716b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c399c22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9450],\n",
       "        [-0.8675],\n",
       "        [ 0.0469],\n",
       "        [ 0.0469],\n",
       "        [-0.4577]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the initial weights \n",
    "W = torch.randn((27, 1))\n",
    "\n",
    "# @ is the matrix multiplication operator in PyTorch\n",
    "xenc @ W\n",
    "\n",
    "# (5, 27) @ (27, 1) becomes (5, 1)\n",
    "\n",
    "# We see the 5 activations of this neuron on these 5 inputs. \n",
    "# We evaluated all 5 in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "329176a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4050, -0.9299, -0.6481,  0.6235,  0.5574, -1.7058, -0.6512,  0.5664,\n",
       "          2.8943, -0.7491,  2.2840, -0.8827, -0.2373, -0.0858, -0.1877,  1.7181,\n",
       "          1.3067,  0.0894,  0.8894,  0.0924,  1.5342,  2.4360,  0.5505, -1.0171,\n",
       "         -0.2543, -1.1197, -1.3539],\n",
       "        [ 0.9570, -0.4897,  0.7848, -0.4547, -0.8783, -0.9774,  2.1470, -1.2373,\n",
       "         -0.4719, -0.0069,  0.5320,  0.7570, -0.6618, -0.9027,  0.5663, -1.1756,\n",
       "          0.1682,  0.5100,  0.9608,  0.9688,  0.2037,  1.7070,  1.0509,  0.5342,\n",
       "          0.2714,  0.7632,  0.2250],\n",
       "        [-1.7065, -1.0598, -0.0503, -1.4475,  1.7381, -0.7777,  0.5428, -0.3042,\n",
       "          1.3993,  2.1054, -0.5674, -1.8728, -2.2653,  1.1335,  0.1366,  0.0361,\n",
       "         -0.5821, -1.3296, -1.5413, -0.5854,  1.1948,  0.4949,  0.3228,  0.7131,\n",
       "          0.9490, -1.1713,  0.2036],\n",
       "        [-1.7065, -1.0598, -0.0503, -1.4475,  1.7381, -0.7777,  0.5428, -0.3042,\n",
       "          1.3993,  2.1054, -0.5674, -1.8728, -2.2653,  1.1335,  0.1366,  0.0361,\n",
       "         -0.5821, -1.3296, -1.5413, -0.5854,  1.1948,  0.4949,  0.3228,  0.7131,\n",
       "          0.9490, -1.1713,  0.2036],\n",
       "        [-1.8960, -1.4478, -0.5423, -0.7828,  0.9439, -2.2212,  1.2269, -1.7259,\n",
       "          1.6215, -0.6484,  0.2888,  3.0736,  1.1277, -0.8399,  1.8475,  1.9781,\n",
       "         -0.3804, -0.3859,  1.9163, -0.4891,  0.3854, -1.2083, -1.0433,  1.1453,\n",
       "         -1.8938, -0.2578,  0.8527]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the initial weights - but now use 27\n",
    "W = torch.randn((27, 27))\n",
    "\n",
    "# @ is the matrix multiplication operator in PyTorch\n",
    "xenc @ W\n",
    "\n",
    "# (5, 27) @ (27, 27) -> (5, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66bae936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc @ W).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0e231fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1335)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for every 27 neurons, what is the firing rate \n",
    "\n",
    "# example\n",
    "(xenc @ W)[3, 13] # is giving us the firing rate of the 13th neuron looking at the 3rd input \n",
    "# it was achieved using the dot product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f237637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99e29a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0858, -0.8399, -0.6295, -0.7229,  1.4068, -0.9027,  2.1869, -1.1000,\n",
       "        -1.3257, -0.2713,  1.0402,  1.4334,  0.0892,  1.1335, -0.9647, -0.4689,\n",
       "        -0.8481,  1.4082,  0.8332,  1.0009, -0.7036,  0.7822,  0.8614,  0.7214,\n",
       "         1.7862,  2.1065,  0.0344])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:,  13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca28814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1335)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc[3] * W[:, 13]).sum() # the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218291c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopped at 1:19:11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
